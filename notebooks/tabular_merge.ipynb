{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import pickle\n",
    "from dateutil import relativedelta\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API call for redcap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def api_call(url, query, logger=None):\n",
    "    \"\"\" helper function to make API calls to RedCap\n",
    "    \"\"\"\n",
    "    r = requests.post(url, data=query, verify=False)\n",
    "    http_status = str(r.status_code)\n",
    "    print(f'HTTP Status: {http_status}')\n",
    "\n",
    "    if http_status == \"200\":\n",
    "        query_results = r.json()\n",
    "        query_df = pd.DataFrame(query_results)\n",
    "\n",
    "    else:\n",
    "        print(f\"RedCap API request Failed with HTTP Status: {http_status}\")\n",
    "        query_df = None\n",
    "        \n",
    "    return query_df\n",
    "\n",
    "def get_inventory_count(df, index_col, availability_indicators):\n",
    "    \"\"\" helper function to count participants with recorded data in redcap\n",
    "    \"\"\"\n",
    "    assess_cols = df.columns.drop(index_col)\n",
    "\n",
    "    if availability_indicators == 'number':\n",
    "        df = df.replace(\"\", np.nan)\n",
    "        df[assess_cols] = df[assess_cols].astype(np.float64)\n",
    "\n",
    "    inventory = {}\n",
    "    for col in assess_cols:        \n",
    "        if availability_indicators == 'number':\n",
    "            availability_count = df[~df[col].isna()][index_col].nunique()\n",
    "        else:\n",
    "            availability_count = df[df[col].isin(availability_indicators)][index_col].nunique()\n",
    "        inventory[col] = availability_count\n",
    "    return inventory\n",
    "\n",
    "def get_available_data(config_json, DATASET_ROOT, var_name, preferred_var_source=\"primary\"):\n",
    "    \"\"\" Get data for given variables from available sources\n",
    "        All return dataframes should have participant_id and visit_id as index\n",
    "    \"\"\"\n",
    "    config_data = json.load(open(config_json))\n",
    "    data_sources = config_data['data_sources']\n",
    "    variable_info = config_data['variables'][var_name]\n",
    "    variable_type = variable_info[\"type\"]\n",
    "    variable_sources = variable_info[\"sources\"]\n",
    "\n",
    "    if preferred_var_source == \"primary\":\n",
    "        selected_var_source = variable_info['primary_source']\n",
    "        selected_var_instrument = variable_info['primary_instrument']\n",
    "    elif preferred_var_source == \"secondary\":\n",
    "        selected_var_source = variable_info['secondary_source']\n",
    "        selected_var_instrument = variable_info['secondary_instrument']\n",
    "    else:\n",
    "        print(f\"Using preferred source {preferred_var_source} for variable {var_name}\")\n",
    "        preferred_var_data_source = preferred_var_source[\"data_source\"]\n",
    "        preferred_var_instrument = preferred_var_source[\"instrument\"]\n",
    "\n",
    "        if preferred_var_data_source not in variable_sources.keys():\n",
    "            print(f\"Preferred data source {preferred_var_data_source} not available for variable {var_name}\")\n",
    "            return None\n",
    "        else:\n",
    "            selected_var_source = preferred_var_data_source\n",
    "\n",
    "        if preferred_var_instrument not in variable_sources[selected_var_source].keys():\n",
    "            print(f\"Preferred var instrument {preferred_var_instrument} not available for variable {var_name}\")\n",
    "            return None\n",
    "        else:\n",
    "            selected_var_instrument = preferred_var_instrument\n",
    "\n",
    "    print(f\"Using variable {var_name} from source {selected_var_source} and instrument {selected_var_instrument}\")\n",
    "\n",
    "    external_var_cols = variable_sources[selected_var_source][selected_var_instrument]\n",
    "\n",
    "    # Get data from primary source\n",
    "    var_file = data_sources[selected_var_source][selected_var_instrument][\"path\"]\n",
    "    var_file_path = f\"{DATASET_ROOT}/{var_file}\"\n",
    "    var_file_index = data_sources[selected_var_source][selected_var_instrument][\"index_cols\"]\n",
    "\n",
    "    var_df = pd.read_csv(var_file_path)\n",
    "    selected_var_cols = list(set(var_file_index + external_var_cols))\n",
    "    var_df = var_df[selected_var_cols]\n",
    "    \n",
    "    if (variable_type == \"date\") & (len(external_var_cols) == 1):\n",
    "        var_df[external_var_cols[0]] = pd.to_datetime(var_df[external_var_cols[0]], errors=\"coerce\", dayfirst=False)\n",
    "\n",
    "    if (len(external_var_cols) == 1):\n",
    "        var_df = var_df.rename(columns={external_var_cols[0]:var_name})\n",
    "    \n",
    "    return var_df\n",
    "\n",
    "def get_age_at_visit(df, date_col, age_col, dob_col=\"dob\", rounding_digits=2, age_range=(0,100)):\n",
    "    \"\"\" Get age at visit. Expects column name to be: var_date \"\"\"\n",
    "    \n",
    "    df[age_col] = df[date_col] - df[dob_col]\n",
    "    df[age_col] = np.round(df[age_col].dt.days / 365.25, rounding_digits)\n",
    "\n",
    "    if (len(df[df[age_col] > 100]) | len(df[df[age_col] < 0])):\n",
    "        print(f\"Warning: Age values outside range {age_range} for variable {var}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ROOT = \"/home/nikhil/projects/Parkinsons/qpn/\"\n",
    "\n",
    "# Current nipoppy release\n",
    "current_release = \"Oct_2024\"\n",
    "\n",
    "data_release_dir = f\"{DATASET_ROOT}/releases/{current_release}/\"\n",
    "tabular_data_release_dir = f\"{data_release_dir}/tabular/\"\n",
    "data_publish_release_dir = f\"{DATASET_ROOT}/releases/qpn-nipoppy-R1/\"\n",
    "tabular_data_publish_release_dir = f\"{data_publish_release_dir}/tabular/\"\n",
    "\n",
    "redcap_release_dir = f\"{data_release_dir}tabular/redcap/chunked/\"\n",
    "# redcap_chunked_report_COPY = f\"{redcap_release_dir}/1. COPN-QPNDataMoCAUPDRSNeur_DATA_LABELS_2024-06-19_0910_copy.xlsx\"\n",
    "# colleted_redcap_report_file = f\"{redcap_release_dir}/redcap_chunked_report.csv\"\n",
    "\n",
    "redcap_legacy_updrs_file = f\"{redcap_release_dir}/COPN-QPNMDSUPDRS_DATA_LABELS_2024-06-19_0945.xlsx\"\n",
    "redcap_legacy_moca_file = f\"{redcap_release_dir}/COPN-QPNMoCA_DATA_LABELS_2024-06-19_0938.xlsx\"\n",
    "\n",
    "filtered_legacy_updrs_file = f\"{redcap_release_dir}/legacy_updrs.csv\"\n",
    "collated_moca_file = f\"{redcap_release_dir}/redcap_and_legacy_moca.csv\"\n",
    "\n",
    "demo_config_json = \"../configs/demographics.json\"\n",
    "pheno_config_json = \"../configs/pheno.json\"\n",
    "\n",
    "# Special cohort inclusion/exclusion criteria files\n",
    "# These files are used to filter participants based on certain criteria - typically would go inside `demographics.csv` \n",
    "## Roche participant list\n",
    "roche_participant_list_csv = f\"{tabular_data_release_dir}/recruitment/roche_participants.csv\"\n",
    "retracted_participant_list_csv = f\"{tabular_data_release_dir}/recruitment/retracted_participants.csv\"\n",
    "\n",
    "# Neuromelanin cohort\n",
    "neuromelanin_participant_list_csv = f\"{tabular_data_release_dir}/recruitment/MRI_NM_LORIS_map.csv\"\n",
    "\n",
    "# output files\n",
    "demographics_file = f\"{tabular_data_release_dir}/demographics.csv\"\n",
    "mri_session_date_file = f\"{tabular_data_release_dir}/mri_info/mri_sessions.csv\"\n",
    "updrs_file = f\"{tabular_data_release_dir}/assessments/updrs.csv\"\n",
    "moca_file = f\"{tabular_data_release_dir}/assessments/moca.csv\"\n",
    "dx_file = f\"{tabular_data_release_dir}/assessments/diagnosis.csv\"\n",
    "hy_file = f\"{tabular_data_release_dir}/assessments/hy.csv\"\n",
    "neuropsych_file = f\"{tabular_data_release_dir}/assessments/neuropsych.csv\"\n",
    "\n",
    "# publish-release files \n",
    "publish_demographics_file = f\"{tabular_data_publish_release_dir}/demographics.csv\"\n",
    "publish_mri_session_date_file = f\"{tabular_data_publish_release_dir}/mri_info/mri_sessions.csv\"\n",
    "publish_updrs_file = f\"{tabular_data_publish_release_dir}/assessments/updrs.csv\"\n",
    "publish_moca_file = f\"{tabular_data_publish_release_dir}/assessments/moca.csv\"\n",
    "publish_dx_file = f\"{tabular_data_publish_release_dir}/assessments/diagnosis.csv\"\n",
    "publish_hy_file = f\"{tabular_data_publish_release_dir}/assessments/hy.csv\"\n",
    "publish_neuropsych_file = f\"{tabular_data_publish_release_dir}/assessments/neuropsych.csv\"\n",
    "\n",
    "# bagel needs to be a tsv file\n",
    "bagel_file = f\"{tabular_data_release_dir}/bagels/tabular_bagel.tsv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardized index names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_event_name = \"Baseline (Arm 1: C-OPN)\"\n",
    "\n",
    "## redcap event name variations\n",
    "config_data = json.load(open(demo_config_json))\n",
    "data_sources = config_data['data_sources']\n",
    "redcap_data_sources = data_sources['redcap']\n",
    "\n",
    "redcap_field_name_map = {}\n",
    "\n",
    "for instrument in redcap_data_sources.keys():\n",
    "    index_cols = redcap_data_sources[instrument]['index_cols']\n",
    "    record_id = index_cols[0]\n",
    "    event_name = index_cols[1]\n",
    "\n",
    "    redcap_field_name_map[record_id] = \"participant_id\"\n",
    "    redcap_field_name_map[event_name] = \"redcap_event_name\"\n",
    "print(f\"redcap_field_name_map: {redcap_field_name_map}\")\n",
    "\n",
    "# legacy participant_id variations in DOB and BD_RPQ\n",
    "legacy_field_name_map = {}\n",
    "legacy_field_name_map['Record ID'] = \"participant_id\"\n",
    "legacy_field_name_map['Patient #'] = \"participant_id\"\n",
    "legacy_field_name_map['Name of visit (V01, V02, V03)'] = \"visit\"\n",
    "print(f\"legacy_field_name_map: {legacy_field_name_map}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update RedCAP reports through API \n",
    "(Not updating extended report since it has to come from Sarah)\n",
    "- \"global_records_query\"\n",
    "- \"QPN MoCA-UPDRS-Neuropsy data_Sarah\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_redcap_reports = False\n",
    "\n",
    "redcap_report_list = [\"MoCA_all_participants_Dx_confirmations\"] #[\"MDSUPDRS-1_Base\"] #[\"Demographic QPN\", \"global_records_query\", \"QPN MoCA-UPDRS-Neuropsy data_Sarah\"]\n",
    "if update_redcap_reports:\n",
    "    redcap_config_json = f\"{DATASET_ROOT}/proc/.redcap.json\"\n",
    "    redcap_config = json.load(open(redcap_config_json))\n",
    "    url = redcap_config[\"url\"]\n",
    "    \n",
    "    for redcap_report in redcap_report_list:\n",
    "        print(f\"Getting data for RedCap report: {redcap_report}\")\n",
    "        records_query = redcap_config[\"queries\"][redcap_report]\n",
    "        query_df = api_call(url, records_query, logger=None)\n",
    "        report_csv = f\"{tabular_data_release_dir}/redcap/{redcap_report}.csv\"\n",
    "        query_df.to_csv(report_csv, index=False)\n",
    "        print(f\"Saved RedCap report to {report_csv}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_cols = query_df.columns[query_df.columns.str.contains(\"dream\", case=False)]\n",
    "# list(selected_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Available participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QPN_participants_df = get_available_data(demo_config_json,data_release_dir,\"participant_id\")\n",
    "QPN_participants = QPN_participants_df[\"participant_id\"].unique()\n",
    "n_participants = len(QPN_participants)\n",
    "session_counts = QPN_participants_df[\"participant_id\"].value_counts()\n",
    "print(f\"Number of participants: {n_participants}\")\n",
    "\n",
    "### Retracted participants\n",
    "print(f\"Removing retracted participants from the dataset\")\n",
    "retracted_participants_df = pd.read_csv(retracted_participant_list_csv)\n",
    "retracted_participants = retracted_participants_df[\"participant_id\"].unique()\n",
    "print(f\"removing following {len(retracted_participants)} participants from the dataset: {retracted_participants}\")\n",
    "QPN_participants_df = QPN_participants_df[~QPN_participants_df[\"participant_id\"].isin(retracted_participants)].copy()\n",
    "\n",
    "QPN_participants = QPN_participants_df[\"participant_id\"].unique()\n",
    "n_participants = len(QPN_participants)\n",
    "session_counts = QPN_participants_df[\"participant_id\"].value_counts()\n",
    "print(f\"Number of participants: {n_participants}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collate chunked RedCap data\n",
    "- The new generate report is formatted as mutli-tab excel spreadsheet based on redcap-event. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regenerate_collated_report = False\n",
    "\n",
    "# if regenerate_collated_report:\n",
    "#     sheet_names = [\"Baseline (without CHQ)\",\"F-U 12months & MNI\",\"F-U 18months & MNI\", \"F-U 24months & MNI\",\n",
    "#                 \"F-U 12months & PD, UDM\", \"F-U 18months & PD, UDM\", \"F-U 24months & PD, UDM\"]\n",
    "#     redcap_chunked_report_df = pd.DataFrame()\n",
    "#     for sheet_name in sheet_names:\n",
    "#         _df = pd.read_excel(redcap_chunked_report_COPY, sheet_name=sheet_name, engine='openpyxl')\n",
    "#         _df = _df[_df[\"Record ID:\"].isin(QPN_participants)]  \n",
    "#         redcap_chunked_report_df = pd.concat([redcap_chunked_report_df, _df], axis=0)\n",
    "#         print(f\"Sheet: {sheet_name} - Shape: {_df.shape}\")\n",
    "#         print(f\"redcap_chunked_report_df - Shape: {redcap_chunked_report_df.shape}\")\n",
    "\n",
    "#     print(f\"Saving collated redcap report to {redcap_release_dir}/redcap_chunked_report.csv\")\n",
    "#     redcap_chunked_report_df.to_csv(collated_redcap_report_file, index=False)\n",
    "\n",
    "# else:\n",
    "#     print(f\"Loading collated redcap report from {redcap_release_dir}/redcap_chunked_report.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collate and calculate legacy UPDRS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regenerate_legacy_data = False\n",
    "\n",
    "if regenerate_legacy_data:\n",
    "    legacy_updrs_df = pd.read_excel(redcap_legacy_updrs_file, engine='openpyxl')\n",
    "\n",
    "    all_updrs3_cols = legacy_updrs_df.columns[legacy_updrs_df.columns.str.startswith(\"Updrs_3\")]\n",
    "    all_legacy_cols = legacy_updrs_df.columns[legacy_updrs_df.columns.str.endswith(\".1\")]\n",
    "\n",
    "    legacy_updrs3_cols = list(set(all_updrs3_cols) & set(all_legacy_cols))\n",
    "\n",
    "    legacy_total_cols = ['Part I: Non-Motor Aspects of Experiences of Daily Living (nM-EDL).1',\n",
    "                        'Part II: Motor Aspects of Experiences of Daily Living (M-EDL).1',\t\n",
    "                        'Part III: Motor Examination.1',\n",
    "                        'Part IV: Motor Complications.1']\n",
    "\n",
    "    legacy_admin_cols = ['Record ID:',\t'Event Name',\n",
    "                        'Assessment completed:     Évaluation remplie:  .1',\n",
    "                        'Assessment completed by:     Évaluation complétée par:.1',\n",
    "                        'How was the MDS-UPDRS administered?   Comment le MDS-UPDRS a-t-il été administré?.1']\n",
    "\n",
    "\n",
    "    legacy_filter_cols = legacy_admin_cols + legacy_total_cols + legacy_updrs3_cols\n",
    "\n",
    "    legacy_updrs_filtered_df = legacy_updrs_df.loc[:, legacy_filter_cols]\n",
    "\n",
    "    legacy_updrs_filtered_df = legacy_updrs_filtered_df.dropna(subset=legacy_updrs3_cols, how='all')\n",
    "\n",
    "    # Filter out two subjects that have all UPDRS subscore (most likely not legacy instrument)\n",
    "    legacy_updrs_filtered_df = legacy_updrs_filtered_df[legacy_updrs_filtered_df[\"Updrs_3_16_l value.1\"].isna()]\n",
    "\n",
    "    n_legacy_participants = legacy_updrs_filtered_df[\"Record ID:\"].nunique()\n",
    "\n",
    "    print(f\"Number of participants with legacy UPDRS data: {n_legacy_participants}\")\n",
    "\n",
    "    print(\"Summing all UPDRS3 sub-scores\")\n",
    "    legacy_updrs_filtered_df[\"legacy_updrs3\"] = legacy_updrs_filtered_df[legacy_updrs3_cols].sum(axis=1)\n",
    "    legacy_updrs_filtered_df[\"Event Name\"] = \"pre-redcap-baseline-1 (legacy)\"\n",
    "\n",
    "    print(f\"Saving filtered legacy UPDRS data to {filtered_legacy_updrs_file}\")\n",
    "    legacy_updrs_filtered_df.to_csv(filtered_legacy_updrs_file, index=False)\n",
    "\n",
    "    legacy_updrs_filtered_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collate and calculate legacy MoCA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regenerate_legacy_data = False\n",
    "\n",
    "if regenerate_legacy_data:\n",
    "    moca_df = pd.read_excel(redcap_legacy_moca_file, engine='openpyxl')\n",
    "\n",
    "    first_legacy_cols = moca_df.columns[moca_df.columns.str.endswith(\".1\")]\n",
    "    second_legacy_cols = moca_df.columns[moca_df.columns.str.endswith(\".2\")]\n",
    "\n",
    "    index_cols = ['Record ID:',\t'Event Name']\n",
    "    first_legacy_moca_df = moca_df.loc[:, index_cols + list(first_legacy_cols)]\n",
    "    second_legacy_moca_df = moca_df.loc[:, index_cols + list(second_legacy_cols)]\n",
    "\n",
    "    n_first_legacy_participants = first_legacy_moca_df[\"Record ID:\"].nunique()\n",
    "    n_second_legacy_participants = second_legacy_moca_df[\"Record ID:\"].nunique()\n",
    "\n",
    "    print(f\"Number of participants with first legacy MoCA data: {n_first_legacy_participants}\")\n",
    "    print(f\"Number of participants with second legacy MoCA data: {n_second_legacy_participants}\")\n",
    "\n",
    "    # merge first and second legacy moca data\n",
    "    moca_cols = first_legacy_cols.str.replace(\".1\",\"\")\n",
    "    first_legacy_cols_dict = dict(zip(first_legacy_cols, moca_cols))\n",
    "    second_legacy_cols_dict = dict(zip(second_legacy_cols, moca_cols))\n",
    "\n",
    "    first_legacy_moca_df = first_legacy_moca_df.rename(columns=first_legacy_cols_dict)\n",
    "    first_legacy_moca_df[\"Event Name\"] = \"pre-redcap-baseline-1 (legacy)\"\n",
    "\n",
    "    second_legacy_moca_df = second_legacy_moca_df.rename(columns=second_legacy_cols_dict)\n",
    "    second_legacy_moca_df[\"Event Name\"] = \"pre-redcap-baseline-2 (legacy)\"\n",
    "\n",
    "    legacy_moca_df = pd.concat([first_legacy_moca_df, second_legacy_moca_df], axis=0)\n",
    "\n",
    "    na_check_cols = legacy_moca_df.columns[legacy_moca_df.columns.str.startswith(\"TOTAL\")]\n",
    "\n",
    "    legacy_moca_df = legacy_moca_df.dropna(subset=na_check_cols, how='all')\n",
    "\n",
    "    n_legacy_participants = legacy_moca_df[\"Record ID:\"].nunique()\n",
    "    legacy_visit_counts = legacy_moca_df[\"Event Name\"].value_counts()\n",
    "\n",
    "    print(f\"Number of participants with legacy MoCA data: {n_legacy_participants}\")\n",
    "    print(f\"legacy_visit_counts MoCA data: {legacy_visit_counts}\")\n",
    "\n",
    "\n",
    "    # Merge legacy data with redcap visit data \n",
    "    print(\"-\"*50)\n",
    "    print(\"Merging redcap and legacy MoCA data\")\n",
    "    \n",
    "    redcap_moca_df = moca_df.loc[:, index_cols + list(moca_cols)]\n",
    "    n_redcap_participants = redcap_moca_df[\"Record ID:\"].nunique()\n",
    "    redcap_events = redcap_moca_df[\"Event Name\"].unique()\n",
    "    print(f\"Number of participants with redcap MoCA data: {n_redcap_participants}\")\n",
    "    print(f\"redcap_events MoCA data: {redcap_events}\")\n",
    "\n",
    "    redcap_and_legacy_moca_df = pd.concat([redcap_moca_df, legacy_moca_df], axis=0)\n",
    "    n_redcap_participants = redcap_and_legacy_moca_df[\"Record ID:\"].nunique()\n",
    "    redcap_events = redcap_and_legacy_moca_df[\"Event Name\"].unique()\n",
    "    print(f\"Number of participants with redcap and legacy MoCA data: {n_redcap_participants}\")\n",
    "    print(f\"redcap_events MoCA data: {redcap_events}\")\n",
    "\n",
    "    print(f\"Saving filtered legacy MoCA data to {collated_moca_file}\")\n",
    "    redcap_and_legacy_moca_df.to_csv(collated_moca_file, index=False)\n",
    "\n",
    "    legacy_moca_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch demographic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_vars = [\"dob\", \"enrollment_group\", \"sex\", \"education\"]\n",
    "# vars_with_secondary_source = [\"dob\"]\n",
    "\n",
    "config_json = demo_config_json\n",
    "index_cols = [\"participant_id\", \"redcap_event_name\"]\n",
    "\n",
    "demo_var_df = pd.DataFrame()\n",
    "for var in demo_vars:\n",
    "    _df = get_available_data(config_json,data_release_dir,var)\n",
    "    _df = _df.rename(columns=redcap_field_name_map)\n",
    "    _df = _df.rename(columns=legacy_field_name_map)\n",
    "    _df = _df[_df[\"participant_id\"].isin(QPN_participants)].copy()\n",
    "\n",
    "    if demo_var_df.empty:\n",
    "        demo_var_df = _df\n",
    "    else:\n",
    "        demo_var_df = pd.merge(demo_var_df, _df, on=index_cols, how=\"outer\")   \n",
    "\n",
    "\n",
    "# add only DoB from seconday source\n",
    "var = \"dob\"\n",
    "print(f\"**Getting data from the secondary source for dob**\")\n",
    "legacy_dob_df = get_available_data(config_json,data_release_dir,var,preferred_var_source=\"secondary\")\n",
    "legacy_dob_df = legacy_dob_df.rename(columns=legacy_field_name_map)\n",
    "legacy_dob_df = legacy_dob_df.rename(columns={var:var+\"_secondary\"})\n",
    "\n",
    "participants_with_missing_value_in_primary = demo_var_df[(demo_var_df[\"redcap_event_name\"]==baseline_event_name) & (demo_var_df[var].isna())][\"participant_id\"].unique()\n",
    "legacy_dob_df = legacy_dob_df[legacy_dob_df[\"participant_id\"].isin(participants_with_missing_value_in_primary)].copy()\n",
    "\n",
    "demo_var_df = pd.merge(demo_var_df, legacy_dob_df, on=[\"participant_id\"], how=\"left\")\n",
    "demo_var_df[var] = demo_var_df[var].fillna(demo_var_df[\"dob_secondary\"])\n",
    "\n",
    "\n",
    "demo_participants = demo_var_df[\"participant_id\"].unique()\n",
    "n_demo_participants = len(demo_participants)\n",
    "print('-'*50)\n",
    "print(f\"Number of participants with demographics data: {n_demo_participants}\")\n",
    "print('-'*50)\n",
    "\n",
    "demo_redcap_events = demo_var_df[\"redcap_event_name\"].unique()\n",
    "print(f\"Demographics data available for events: {demo_redcap_events}\")\n",
    "print('-'*50)\n",
    "\n",
    "# Only keep data for baseline event\n",
    "print('-'*50)\n",
    "print(f\"Keeping data for event: {baseline_event_name} (i.e. static variables)\")\n",
    "print(f\"All temporal data goes into assessment files\")\n",
    "print('-'*50)\n",
    "demo_var_df = demo_var_df[demo_var_df[\"redcap_event_name\"]==baseline_event_name].copy()\n",
    "\n",
    "for var in demo_vars:\n",
    "    n_unique = demo_var_df[var].nunique()\n",
    "    n_missing = demo_var_df[var].isna().sum()\n",
    "    print(f\"Var: {var}, n_unique: {n_unique}, n_missing: {n_missing} (out of {n_demo_participants})\")\n",
    "\n",
    "# demo_var_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tag / retract certain participants based on special criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Roche tag \n",
    "roche_participants_df = pd.read_csv(roche_participant_list_csv)\n",
    "roche_participants = roche_participants_df[\"participant_id\"].unique()\n",
    "\n",
    "print(f\"Number of Roche participants: {len(roche_participants)}\")\n",
    "\n",
    "demo_var_df[\"recruitment_cohort\"] = \"QPN\"\n",
    "demo_var_df.loc[demo_var_df[\"participant_id\"].isin(roche_participants),\"recruitment_cohort\"] = \"Roche\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save demographics data **without the DOB** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_save_cols = [\"participant_id\", \"redcap_event_name\", \"recruitment_cohort\", \"enrollment_group\", \"sex\", \"education\"]\n",
    "demo_var_without_dob_df = demo_var_df[demo_save_cols]\n",
    "demo_var_without_dob_df.to_csv(demographics_file, index=False)\n",
    "print(f\"Saved demographics data to {demographics_file}\")\n",
    "demo_var_without_dob_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find records with phenotypic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_vars = [\"updrs_scores\", \"moca_scores\", \"updrs_date\", \"moca_date\",\n",
    "              \"diagnosis_date\", \"diagnosis_confirmation\", \"diagnosis_certainty\"] #\"legacy_updrs3_scores\", \"legacy_updrs3_date\",\n",
    "\n",
    "config_json = pheno_config_json\n",
    "index_cols = [\"participant_id\", \"redcap_event_name\"]\n",
    "pheno_var_df = pd.DataFrame()\n",
    "for var in pheno_vars:\n",
    "    _df = get_available_data(config_json,data_release_dir,var)\n",
    "    _df = _df.rename(columns=redcap_field_name_map)\n",
    "    _df = _df.rename(columns=legacy_field_name_map)\n",
    "    _df = _df[_df[\"participant_id\"].isin(QPN_participants)].copy()\n",
    "    if pheno_var_df.empty:\n",
    "        pheno_var_df = _df\n",
    "    else:\n",
    "        pheno_var_df = pd.merge(pheno_var_df, _df, on=index_cols, how=\"outer\")   \n",
    "\n",
    "pheno_participants = pheno_var_df[\"participant_id\"].unique()\n",
    "n_pheno_participants = len(pheno_participants)\n",
    "print('-'*50)\n",
    "print(f\"Number of participants with pheno data: {n_pheno_participants}\")\n",
    "print('-'*50)\n",
    "\n",
    "pheno_redcap_events = pheno_var_df[\"redcap_event_name\"].unique()\n",
    "print(f\"Pheno data available for events: {pheno_redcap_events}\")\n",
    "print('-'*50)\n",
    "\n",
    "for var in pheno_var_df.columns:\n",
    "    for redcap_event in pheno_redcap_events:\n",
    "        if var not in index_cols:\n",
    "            pheno_var_event_df = pheno_var_df[pheno_var_df[\"redcap_event_name\"]==redcap_event].copy()\n",
    "            n_pheno_var_event_participants = pheno_var_event_df[\"participant_id\"].nunique()\n",
    "            if pheno_var_event_df[var].nunique() > 0:    \n",
    "                print(f\"Var: {var}, Event: {redcap_event}\")\n",
    "                n_unique = pheno_var_event_df[var].nunique()\n",
    "                n_missing = pheno_var_event_df[var].isna().sum()\n",
    "                print(f\"n_unique: {n_unique}, n_missing: {n_missing} (out of {n_pheno_var_event_participants})\")\n",
    "    print('-'*50)\n",
    "\n",
    "pheno_var_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tag legacy participants for UPDRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_vars = [\"legacy_updrs3_scores\", \"legacy_updrs3_date\"]\n",
    "\n",
    "config_json = pheno_config_json\n",
    "index_cols = [\"participant_id\", \"redcap_event_name\"]\n",
    "legacy_var_df = pd.DataFrame()\n",
    "for var in pheno_vars:\n",
    "    _df = get_available_data(config_json,data_release_dir,var)\n",
    "    _df = _df.rename(columns=redcap_field_name_map)\n",
    "    _df = _df.rename(columns=legacy_field_name_map)\n",
    "    # _df = _df[_df[\"participant_id\"].isin(QPN_participants)].copy()\n",
    "    if legacy_var_df.empty:\n",
    "        legacy_var_df = _df\n",
    "    else:\n",
    "        legacy_var_df = pd.merge(legacy_var_df, _df, on=index_cols, how=\"outer\")   \n",
    "\n",
    "n_legacy_participants = legacy_var_df[\"participant_id\"].nunique()\n",
    "print(f\"Number of participants with legacy data: {n_legacy_participants}\")\n",
    "\n",
    "legacy_var_df[\"redcap_event_name\"] = \"legacy-updrs3\"\n",
    "legacy_var_df = legacy_var_df.rename(columns={\"legacy_updrs3_date\":\"updrs_date\"})\n",
    "\n",
    "# Append phono_var_df with legacy updrs data\n",
    "pheno_var_df = pd.concat([pheno_var_df, legacy_var_df], axis=0)\n",
    "\n",
    "legacy_var_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append legacy MoCA report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_vars = [\"legacy_moca_scores\", \"legacy_moca_date\"]\n",
    "\n",
    "config_json = pheno_config_json\n",
    "index_cols = [\"participant_id\", \"redcap_event_name\"]\n",
    "legacy_var_df = pd.DataFrame()\n",
    "for var in pheno_vars:\n",
    "    _df = get_available_data(config_json,data_release_dir,var)\n",
    "    _df = _df.rename(columns=redcap_field_name_map)\n",
    "    _df = _df.rename(columns=legacy_field_name_map)\n",
    "    # _df = _df[_df[\"participant_id\"].isin(QPN_participants)].copy()\n",
    "    if legacy_var_df.empty:\n",
    "        legacy_var_df = _df\n",
    "    else:\n",
    "        legacy_var_df = pd.merge(legacy_var_df, _df, on=index_cols, how=\"outer\")   \n",
    "\n",
    "n_legacy_participants = legacy_var_df[\"participant_id\"].nunique()\n",
    "print(f\"Number of participants with legacy data: {n_legacy_participants}\")\n",
    "\n",
    "legacy_var_df[\"redcap_event_name\"] = \"legacy-moca\"\n",
    "legacy_var_df = legacy_var_df.rename(columns={\"legacy_moca_date\":\"moca_date\"})\n",
    "\n",
    "# Append phono_var_df with legacy updrs data\n",
    "pheno_var_df = pd.concat([pheno_var_df, legacy_var_df], axis=0)\n",
    "\n",
    "legacy_var_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign final Dx group label for analysis based on the following rules:\n",
    "- formula\n",
    "1. HC if enrolment group = \"Healthy control\"\n",
    "2. PD if diagnostic certainty =! nan or \"Is not PD / N'est pas PD\"\n",
    "3. We shouldn't consider the \"PD in opinion of the treating neurologist\", \"determined diagnosis\", or \"final impression\" fields anymore.\n",
    "\n",
    "- Older formula\n",
    "1. if (in enrollment_report) enrollment_group  == 'Healthy control/Contrôle', then group = 'control'\n",
    "2. else (in the diagnosis report ) if determined_diagnosis == 0 & (final_impression == \"Meets criteria for Parkinson's disease / Répond aux critères de la maladie de Parkinson\") | final_impression == NA), then group = 'pd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_impression_col = \"Final impression / Impression finale\"\t\n",
    "determined_diagnosis_col = \"Determined diagnosis:  If score = 0, Parkinson's Disease (PD)  If score = 1, Progressive Supranuclear Palsy (PSP)  If score = 2, Multiple System Atrophy (MSA)  If score = 3, Corticobasal Syndrome (CBS)  If score = 4, Dementia with Lewy Bodies (DLB)  If score = 5, Frontotemporal Dementia (FTD)  If score = 6, Essential Tremor (ET)  If score = 7, REM Sleep Behaviour Disorder (RBD)\"\n",
    "final_impression_notes_for_PD = [\"Meets criteria for Parkinson's disease / Répond aux critères de la maladie de Parkinson\", np.nan]\n",
    "dx_certainty_col = \"diagnosis_certainty\"\n",
    "\n",
    "control_participants = demo_var_df[demo_var_df[\"enrollment_group\"]==\"Healthy control/Contrôle\"][\"participant_id\"].unique()\n",
    "# older criteria\n",
    "# PD_participants = pheno_var_df[(pheno_var_df[determined_diagnosis_col]==0) \n",
    "#                                & (pheno_var_df[final_impression_col].isin(final_impression_notes_for_PD))][\"participant_id\"].unique()\n",
    "# new criteria based on certainty #\n",
    "valid_dx_certainty = [\"Meets MDS criteria for established PD / Répond aux critères MDS pour un PD établi\",\n",
    "                      \"Meets MDS criteria for probable PD / Répond aux critères MDS pour un PD probable\",\n",
    "                      \"Self-report / Auto-évaluation\",\n",
    "                      \"PD in the opinion of the treating neurologist / PD selon l'avis du neurologue traitant\"]\n",
    "\n",
    "PD_participants = pheno_var_df[pheno_var_df[dx_certainty_col].isin(valid_dx_certainty)][\"participant_id\"].unique()\n",
    "unknown_dx_participants = set(pheno_var_df[\"participant_id\"].unique()) - set(control_participants) - set(PD_participants)\n",
    "\n",
    "redcap_events_for_dx_confirmation = [baseline_event_name] #\"legacy-updrs3\", \"legacy-moca\"\n",
    "pheno_var_df[\"diagnosis_group_for_analysis\"] = np.nan\n",
    "pheno_var_df.loc[(pheno_var_df[\"participant_id\"].isin(control_participants)) \n",
    "                 & (pheno_var_df[\"redcap_event_name\"].isin(redcap_events_for_dx_confirmation)), \n",
    "                 \"diagnosis_group_for_analysis\"] = \"control\"\n",
    "pheno_var_df.loc[(pheno_var_df[\"participant_id\"].isin(PD_participants)) \n",
    "                 & (pheno_var_df[\"redcap_event_name\"].isin(redcap_events_for_dx_confirmation)), \n",
    "                 \"diagnosis_group_for_analysis\"] = \"PD\"\n",
    "pheno_var_df.loc[(pheno_var_df[\"participant_id\"].isin(unknown_dx_participants)) \n",
    "                 & (pheno_var_df[\"redcap_event_name\"].isin(redcap_events_for_dx_confirmation)), \n",
    "                 \"diagnosis_group_for_analysis\"] = \"unknown\"\n",
    "\n",
    "print('-'*50)\n",
    "print(f\"Number of participants with diagnosis data: {len(pheno_var_df['participant_id'].unique())}\")\n",
    "print(f\"Number of control participants: {len(control_participants)}\")\n",
    "print(f\"Number of PD participants: {len(PD_participants)}\")\n",
    "print(f\"Number of unknown diagnosis participants: {len(unknown_dx_participants)}\")\n",
    "print('-'*50)\n",
    "\n",
    "pheno_var_df[index_cols + [\"diagnosis_group_for_analysis\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neuropsych data\n",
    "- Comes from either from Sarah's extended report or BD_RPQ_UPDATE_Neuropsy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuropsych_vars = [\"neuropsy_scores\",\"neuropsy_date\"]\n",
    "\n",
    "config_data = json.load(open(config_json))\n",
    "variable_info = config_data['variables'][neuropsych_vars[0]]\n",
    "variable_sources = variable_info[\"sources\"]\n",
    "neuropsy_source = variable_info['primary_source']\n",
    "\n",
    "print(f\"Using neuropsych data source: {neuropsy_source}\")\n",
    "# local BD_RPQ data\n",
    "if neuropsy_source == \"local\":\n",
    "    index_cols = [\"participant_id\", \"visit\", \"TimePoint (based on REDCap; baseline, 18m, 36m, etc.)\", \"Délai depuis baseline (mois)\"]\n",
    "    \n",
    "# redcap data\n",
    "if neuropsy_source == \"redcap\":\n",
    "    index_cols = [\"participant_id\", \"redcap_event_name\"]\n",
    "\n",
    "    \n",
    "neuropsych_df = pd.DataFrame()\n",
    "for var in neuropsych_vars:\n",
    "    _df = get_available_data(config_json,data_release_dir,var)\n",
    "    _df = _df.rename(columns=redcap_field_name_map)\n",
    "    _df = _df.rename(columns=legacy_field_name_map)\n",
    "    _df = _df[_df[\"participant_id\"].isin(QPN_participants)].copy()\n",
    "\n",
    "    # Fix the decimal / comma issue in the column values\n",
    "    mixed_numeric_dtype_cols = [\n",
    "        \"Copy raw\",\n",
    "        \"Copy time (sec)\",\n",
    "        \"Immediate recall raw\",\n",
    "        \"Immediate recall time (sec)\",\n",
    "        \"Delayed recall raw\",\n",
    "        \"Delayed recall time (sec)\",\n",
    "    ]\n",
    "    for col in _df.columns:\n",
    "        if (col in mixed_numeric_dtype_cols) & (_df[col].astype(str).str.contains(\",\").any()):\n",
    "            _df[col] = _df[col].str.replace(\",\",\".\").astype(float)\n",
    "\n",
    "    if neuropsych_df.empty:\n",
    "        neuropsych_df = _df\n",
    "    else:\n",
    "        neuropsych_df = pd.merge(neuropsych_df, _df, on=index_cols, how=\"left\")   \n",
    "\n",
    "neuropsych_participants = neuropsych_df[\"participant_id\"].unique()\n",
    "n_neuropsych_participants = len(neuropsych_participants)\n",
    "print('-'*50)\n",
    "print(f\"Number of participants with neuropysch data: {n_neuropsych_participants}\")\n",
    "print('-'*50)\n",
    "\n",
    "neuropsych_cols = neuropsych_df.columns.drop(index_cols).tolist()\n",
    "n_neuropsuch_cols = len(neuropsych_cols)\n",
    "print(f\"Neuropsych data available for variables: {n_neuropsuch_cols}\")\n",
    "print('-'*50)\n",
    "\n",
    "# BD_RPQ data\n",
    "if neuropsy_source == \"local\":\n",
    "    neuropsych_visits = neuropsych_df[\"visit\"].unique()\n",
    "\n",
    "# REDCap data\n",
    "if neuropsy_source == \"redcap\":\n",
    "    neuropsych_visits = neuropsych_df[\"redcap_event_name\"].unique()\n",
    "\n",
    "print(f\"neuropsych data available for events: {neuropsych_visits}\")\n",
    "print('-'*50)\n",
    "\n",
    "neuropsych_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic clean-up and data checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix dtypes\n",
    "for series_name, series in neuropsych_df.items():\n",
    "    if \"score\" in series_name:\n",
    "        if series.dtype == 'object':\n",
    "            print(f\"recasting {series_name} to float by replacing , with .\")\n",
    "            neuropsych_df[series_name] = neuropsych_df[series_name].str.replace(\",\",\".\").astype(float)\n",
    "            neuropsych_df.loc[neuropsych_df[series_name]>900, series_name] = np.nan\n",
    "            \n",
    "    # Replace >900 with NaNs\n",
    "    if series.dtype == 'float':\n",
    "        neuropsych_df.loc[neuropsych_df[series_name]>900, series_name] = np.nan\n",
    "\n",
    "# assign redcap_event_name\n",
    "visit_months = [12, 18, 24, 30, 36, 42, 48, 54]\n",
    "month_bins = [9, 15, 21, 27, 33, 39, 45, 51, 57]\n",
    "event_str_suffix = \"Months Follow-Up/Suivi (Arm 1: C-OPN)\"\n",
    "event_names = [f\"{m} {event_str_suffix}\" for m in visit_months]\n",
    "\n",
    "if neuropsy_source == \"local\":\n",
    "    neuropsych_df[\"redcap_event_name\"] = pd.cut(neuropsych_df[\"Délai depuis baseline (mois)\"], bins=month_bins, labels=event_names).astype(str)\n",
    "    neuropsych_df.loc[neuropsych_df[\"TimePoint (based on REDCap; baseline, 18m, 36m, etc.)\"]==\"baseline\", \n",
    "                      \"redcap_event_name\"] = \"Baseline (Arm 1: C-OPN)\"\n",
    "\n",
    "# Merge with pheno_var_df\n",
    "index_cols = [\"participant_id\", \"redcap_event_name\"]\n",
    "pheno_var_df = pd.merge(pheno_var_df, neuropsych_df, on=index_cols, how=\"left\")  \n",
    "\n",
    "pheno_var_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add mri_acq date\n",
    "- Needs to map to redcap_event_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = \"MRI_date\"\n",
    "config_json = pheno_config_json\n",
    "mri_date_df = get_available_data(config_json,data_release_dir,var)\n",
    "mri_date_df[\"MRI_date\"] = pd.to_datetime(mri_date_df[\"MRI_date\"], errors=\"coerce\", dayfirst=False)\n",
    "\n",
    "n_mri_participants = mri_date_df[\"participant_id\"].nunique()\n",
    "print(f\"Number of participants with MRI data: {n_mri_participants}\")\n",
    "\n",
    "n_sessions = mri_date_df[\"session\"].nunique()\n",
    "print(f\"Number of MRI sessions: {n_sessions}\")\n",
    "\n",
    "### Retracted participants\n",
    "print(f\"Removing retracted participants from the dataset\")\n",
    "retracted_participants_df = pd.read_csv(retracted_participant_list_csv)\n",
    "retracted_participants = retracted_participants_df[\"participant_id\"].unique()\n",
    "print(f\"removing following {len(retracted_participants)} participants from the dataset: {retracted_participants}\")\n",
    "mri_date_df = mri_date_df[~mri_date_df[\"participant_id\"].isin(retracted_participants)].copy()\n",
    "\n",
    "participants_with_follow_ups = mri_date_df[mri_date_df[\"participant_id\"].duplicated()][\"participant_id\"].unique()\n",
    "n_participants_with_follow_ups = len(participants_with_follow_ups)\n",
    "print(f\"Number of participants with follow-up MRI: {n_participants_with_follow_ups}\")\n",
    "\n",
    "mri_ses01_date_df = mri_date_df[mri_date_df[\"session\"]==\"ses-01\"].copy()\n",
    "mri_ses01_date_df[\"redcap_event_name\"] = \"Baseline (Arm 1: C-OPN)\"\n",
    "\n",
    "mri_ses02_date_df = mri_date_df[mri_date_df[\"session\"]==\"ses-02\"].copy()\n",
    "mri_ses02_participants = mri_ses02_date_df[\"participant_id\"].unique()\n",
    "print(f\"Number of participants with ses-02 MRI: {len(mri_ses02_participants)}\")\n",
    "\n",
    "baseline_df = mri_ses01_date_df[mri_ses01_date_df[\"participant_id\"].isin(mri_ses02_participants)].set_index(\"participant_id\")\n",
    "followup_df = mri_ses02_date_df.set_index(\"participant_id\")\n",
    "\n",
    "visit_months = [12, 18, 24, 30, 36, 42, 48, 54]\n",
    "month_bins = [9, 15, 21, 27, 33, 39, 45, 51, 57]\n",
    "\n",
    "event_str_suffix = \"Months Follow-Up/Suivi (Arm 1: C-OPN)\"\n",
    "event_names = [f\"{m} {event_str_suffix}\" for m in visit_months]\n",
    "\n",
    "# --- Bin the months --- #\n",
    "followup_df[\"months_since_baseline\"] = followup_df[\"MRI_date\"].dt.to_period('M').astype(int) - baseline_df[\"MRI_date\"].dt.to_period('M').astype(int)\n",
    "followup_df[\"months_since_baseline\"] = followup_df[\"months_since_baseline\"].replace({0:np.nan}) # Some visits get same acq_date from brodacasting merge. \n",
    "\n",
    "followup_df[\"redcap_event_name\"] = pd.cut(followup_df[\"months_since_baseline\"], bins=month_bins, labels=event_names)\n",
    "\n",
    "mri_date_redcap_event_df = pd.concat([mri_ses01_date_df, followup_df.reset_index()], axis=0)\n",
    "# mri_date_redcap_event_df = mri_date_redcap_event_df\n",
    "\n",
    "mri_date_redcap_event_df.sort_values([\"participant_id\",\"session\"]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add MRI date to pheno data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_var_df = pd.merge(pheno_var_df, mri_date_redcap_event_df, on=index_cols, how=\"outer\")  \n",
    "var = \"MRI_date\"\n",
    "for redcap_event in mri_date_redcap_event_df[\"redcap_event_name\"].unique():    \n",
    "    pheno_var_event_df = pheno_var_df[pheno_var_df[\"redcap_event_name\"]==redcap_event].copy()\n",
    "    n_pheno_var_event_participants = pheno_var_event_df[\"participant_id\"].nunique()\n",
    "    if pheno_var_event_df[var].nunique() > 0:    \n",
    "        print(f\"Var: {var}, Event: {redcap_event}\")\n",
    "        n_unique = pheno_var_event_df[var].nunique()\n",
    "        n_missing = pheno_var_event_df[var].isna().sum()\n",
    "        print(f\"n_unique: {n_unique}, n_missing: {n_missing} (out of {n_pheno_var_event_participants})\")\n",
    "pheno_var_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform legacy updrs-III scores into mds-updrs-III scores\n",
    "- Reference: Goetz et al. (2012)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pheno_var_df.groupby([\"redcap_event_name\"])[\"participant_id\"].count())\n",
    "pheno_var_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate left and right side affected\n",
    "pheno_var_df['left'] = (pheno_var_df['Updrs_3_3_lue value'] + pheno_var_df['Updrs_3_3_lle value'] + pheno_var_df['Updrs_3_4_l value'] +\n",
    "              pheno_var_df['Updrs_3_5_l value'] + pheno_var_df['Updrs_3_6_l value'] + pheno_var_df['Updrs_3_8_l value'])\n",
    "\n",
    "pheno_var_df['right'] = (pheno_var_df['Updrs_3_3_rue value'] + pheno_var_df['Updrs_3_3_rle value'] + pheno_var_df['Updrs_3_4_r value'] +\n",
    "               pheno_var_df['Updrs_3_5_r value'] + pheno_var_df['Updrs_3_6_r value'] + pheno_var_df['Updrs_3_8_r value'])\n",
    "\n",
    "# estimate hy score from updrs part 3\n",
    "pheno_var_df[['hy_derived', 'Part III: Motor Examination (harmonized)']] = np.nan\n",
    "# mask_complete = df['Complete?'] != 'Incomplete'\n",
    "pheno_var_df.loc[((pheno_var_df['left'] == 0) | (pheno_var_df['right'] == 0)), 'hy_derived'] = 1\n",
    "pheno_var_df.loc[(pheno_var_df['left'] > 0) & (pheno_var_df['right'] > 0) & (pheno_var_df['Updrs_3_12 value'] == 0), 'hy_derived'] = 2\n",
    "pheno_var_df.loc[(pheno_var_df['left'] > 0) & (pheno_var_df['right'] > 0) & (pheno_var_df['Updrs_3_12 value'] > 0) & \n",
    "                 (pheno_var_df['Updrs_3_10 value'] == 0), 'hy_derived'] = 3\n",
    "pheno_var_df.loc[(pheno_var_df['left'] > 0) & (pheno_var_df['right'] > 0) & (pheno_var_df['Updrs_3_12 value'] > 0) & \n",
    "                 (pheno_var_df['Updrs_3_10 value'] > 0) & (pheno_var_df['Updrs_3_10 value'] < 3), 'hy_derived'] = 4\n",
    "pheno_var_df.loc[(pheno_var_df['left'] > 0) & (pheno_var_df['right'] > 0) & (pheno_var_df['Updrs_3_12 value'] > 0) & \n",
    "                 (pheno_var_df['Updrs_3_10 value'] > 0) & (pheno_var_df['Updrs_3_10 value'] >= 3), 'hy_derived'] = 5\n",
    "\n",
    "# check if updrs version is new or old\n",
    "cols_to_check = [\n",
    "    'Part I: Non-Motor Aspects of Experiences of Daily Living (nM-EDL)',\n",
    "    'Part II: Motor Aspects of Experiences of Daily Living (M-EDL)',\n",
    "    'Part IV: Motor Complications'\n",
    "]\n",
    "mask_old = pheno_var_df[cols_to_check].isnull().all(axis=1)\n",
    "mask_new = pheno_var_df[cols_to_check].notnull().any(axis=1)\n",
    "\n",
    "# convert original uprds to mds-updrs\n",
    "pheno_var_df.loc[mask_new, 'Part III: Motor Examination (harmonized)'] = pheno_var_df['Part III: Motor Examination']\n",
    "pheno_var_df.loc[mask_old & pheno_var_df['hy_derived'].isin([1, 2]), 'Part III: Motor Examination (harmonized)'] = (pheno_var_df['Part III: Motor Examination'] * 1.2) + 2.3\n",
    "pheno_var_df.loc[mask_old & (pheno_var_df['hy_derived'] == 3), 'Part III: Motor Examination (harmonized)'] = (pheno_var_df['Part III: Motor Examination'] * 1.2) + 1.0\n",
    "pheno_var_df.loc[mask_old & pheno_var_df['hy_derived'].isin([4, 5]), 'Part III: Motor Examination (harmonized)'] = (pheno_var_df['Part III: Motor Examination'] * 1.1) + 7.5\n",
    "\n",
    "# drop left and right cols\n",
    "pheno_var_df.drop(columns=['left', 'right', 'hy_derived'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_cols = [\"participant_id\", \"dob\", \"enrollment_group\", \"sex\"]\n",
    "demo_var_df[demo_var_df[\"participant_id\"]==participants_with_follow_ups[0]]\n",
    "baseline_demo_df = demo_var_df[demo_var_df[\"redcap_event_name\"]==\"Baseline (Arm 1: C-OPN)\"][demo_cols].copy()\n",
    "\n",
    "index_cols = [\"participant_id\"] # not using redcap_event_name to allow broadcast of demographics vars\n",
    "tabular_df = pd.merge(pheno_var_df, baseline_demo_df, on=index_cols, how=\"left\")\n",
    "tabular_df[tabular_df[\"participant_id\"]==participants_with_follow_ups[0]]\n",
    "\n",
    "\n",
    "# Get age at visit\n",
    "date_cols = [\"diagnosis_date\", \"updrs_date\", \"moca_date\", \"MRI_date\", \"neuropsy_date\"]\n",
    "\n",
    "date_age_cols_dict = {}\n",
    "for col in date_cols:\n",
    "    date_age_cols_dict[col] = f\"{col.rsplit('_',1)[0]}_age\"\n",
    "\n",
    "age_cols = list(date_age_cols_dict.values())\n",
    "\n",
    "for date_col, age_col in date_age_cols_dict.items():\n",
    "    tabular_df = get_age_at_visit(tabular_df, date_col, age_col)\n",
    "\n",
    "# Generate age column for H&Y score that is identical as updrs_age for a given visit\n",
    "tabular_df[\"hy_age\"] = tabular_df[\"updrs_age\"]\n",
    "\n",
    "# remove DoB from tabular df\n",
    "\n",
    "tabular_df = tabular_df.drop(columns=[\"dob\"])\n",
    "\n",
    "tabular_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save demo, mri_dates, and pheno (dx, updrs, moca, neuropsych) in separate files\n",
    "- remove DoB and other date columns \n",
    "- add age columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_cols = [\"participant_id\", \"redcap_event_name\"]\n",
    "\n",
    "mri_cols = [\"session\", \"MRI_age\"]\n",
    "\n",
    "dx_cols = [ \"Parkinson's disease in opinion of treating neurologist / Maladie de Parkinson selon l'avis du neurologue traitant\",\n",
    "            \"Final impression / Impression finale\",\t\n",
    "            \"Determined diagnosis:  If score = 0, Parkinson's Disease (PD)  If score = 1, Progressive Supranuclear Palsy (PSP)  If score = 2, Multiple System Atrophy (MSA)  If score = 3, Corticobasal Syndrome (CBS)  If score = 4, Dementia with Lewy Bodies (DLB)  If score = 5, Frontotemporal Dementia (FTD)  If score = 6, Essential Tremor (ET)  If score = 7, REM Sleep Behaviour Disorder (RBD)\",\n",
    "            \"diagnosis_certainty\",\n",
    "            \"diagnosis_group_for_analysis\",\n",
    "            \"diagnosis_age\"\n",
    "            ]\n",
    "\n",
    "hy_cols = ['Hoehn and Yahr Stage: ', 'hy_age']\n",
    "\n",
    "updrs_cols = ['Part I: Non-Motor Aspects of Experiences of Daily Living (nM-EDL)',\n",
    "              'Part II: Motor Aspects of Experiences of Daily Living (M-EDL)',\n",
    "              \"Updrs_3_1 value\", \"Updrs_3_2 value\", \"Updrs_3_3_neck value\",\n",
    "              \"Updrs_3_3_rue value\", \"Updrs_3_3_lue value\", \"Updrs_3_3_rle value\",\n",
    "              \"Updrs_3_3_lle value\", \"Updrs_3_4_r value\", \"Updrs_3_4_l value\",\n",
    "              \"Updrs_3_5_r value\", \"Updrs_3_5_l value\", \"Updrs_3_6_r value\",\n",
    "              \"Updrs_3_6_l value\", \"Updrs_3_7_r value\", \"Updrs_3_7_l value\",\n",
    "              \"Updrs_3_8_r value\", \"Updrs_3_8_l value\", \"Updrs_3_9 value\",\n",
    "              \"Updrs_3_10 value\", \"Updrs_3_11 value\", \"Updrs_3_12 value\",\n",
    "              \"Updrs_3_13 value\", \"Updrs_3_14\", \"Updrs_3_15_r value\",\n",
    "              \"Updrs_3_15_l value\", \"Updrs_3_16_r value\", \"Updrs_3_16_l value\",\n",
    "              \"Updrs_3_17_rue value\", \"Updrs_3_17_lue value\", \"Updrs_3_17_rle value\",\n",
    "              \"Updrs_3_17_lle value\", \"Updrs_3_17_lipjaw value\", \"Updrs_3_18 value\",\n",
    "              'Part III: Motor Examination', 'Part III: Motor Examination (harmonized)', \n",
    "              'Part IV: Motor Complications', \n",
    "              'updrs_age',\n",
    "              ]\n",
    "\n",
    "# moca_cols = [\"moca_scores\", \"moca_age\"]\n",
    "moca_cols = [\n",
    "            \"TOTAL SCORE (make sure to include extra point for 12 years or less of education):    SCORE TOTAL (assurez-vous d'inclure un point supplémentaire pour 12 ans ou moins d'éducation) : \",\n",
    "            \"Did the participant receive +1 extra point for 12 years or less of education?    Le participant a-t-il reçu +1 point supplémentaire pour 12 ans ou moins d'études?\",\n",
    "            \"moca_age\"\n",
    "            ]\n",
    "\n",
    "neuropsych_cols = neuropsych_cols + [\"neuropsy_age\"]\n",
    "if \"neuropsy_date\" in neuropsych_cols:\n",
    "    neuropsych_cols.remove(\"neuropsy_date\")\n",
    "\n",
    "mri_df = tabular_df[index_cols + mri_cols]\n",
    "dx_df = tabular_df[index_cols + dx_cols].copy()\n",
    "hy_df = tabular_df[index_cols + hy_cols].copy()\n",
    "updrs_df = tabular_df[index_cols + updrs_cols].copy()\n",
    "moca_df = tabular_df[index_cols + moca_cols].copy()\n",
    "neuropsych_df = tabular_df[index_cols + neuropsych_cols].copy()\n",
    "\n",
    "# filter na rows\n",
    "mri_df = mri_df.dropna(subset=mri_cols, how='all').sort_values([\"redcap_event_name\"], ascending=False).sort_values([\"participant_id\"])\n",
    "dx_df = dx_df.dropna(subset=dx_cols, how='all').sort_values([\"redcap_event_name\"], ascending=False).sort_values([\"participant_id\"])\n",
    "hy_df = hy_df.dropna(subset=hy_cols, how='all').sort_values([\"redcap_event_name\"], ascending=False).sort_values([\"participant_id\"])\n",
    "updrs_df = updrs_df.dropna(subset=updrs_cols, how='all').sort_values([\"redcap_event_name\"], ascending=False).sort_values([\"participant_id\"])\n",
    "moca_df = moca_df.dropna(subset=moca_cols, how='all').sort_values([\"redcap_event_name\"], ascending=False).sort_values([\"participant_id\"])\n",
    "neuropsych_df = neuropsych_df.dropna(subset=neuropsych_cols, how='all').sort_values([\"redcap_event_name\"], ascending=False).sort_values([\"participant_id\"])\n",
    "\n",
    "\n",
    "# Save data to files\n",
    "mri_df.to_csv(mri_session_date_file, index=False)\n",
    "print(f\"Saved MRI session data to {mri_session_date_file}\")\n",
    "\n",
    "dx_df.to_csv(dx_file, index=False)\n",
    "print(f\"Saved diagnosis data to {dx_file}\")\n",
    "\n",
    "hy_df.to_csv(hy_file, index=False)\n",
    "print(f\"Saved H&Y data to {hy_file}\")\n",
    "\n",
    "updrs_df.to_csv(updrs_file, index=False)\n",
    "print(f\"Saved UPDRS data to {updrs_file}\")\n",
    "\n",
    "moca_df.to_csv(moca_file, index=False)\n",
    "print(f\"Saved MoCA data to {moca_file}\")\n",
    "\n",
    "neuropsych_df.to_csv(neuropsych_file, index=False)\n",
    "print(f\"Saved neuropsych data to {neuropsych_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Participant counts per cohort and dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_dx_df = pd.merge(mri_df[[\"participant_id\",\"session\"]], dx_df[[\"participant_id\",\"Final impression / Impression finale\", \"diagnosis_certainty\",\"diagnosis_group_for_analysis\"]], on=[\"participant_id\"], how=\"left\").drop_duplicates()\n",
    "mri_dx_demo_df = pd.merge(mri_dx_df, demo_var_df[[\"participant_id\", \"recruitment_cohort\", \"enrollment_group\"]], on=[\"participant_id\"], how=\"left\").drop_duplicates()\n",
    "mri_dx_demo_df.groupby([\"session\", \"recruitment_cohort\", \"enrollment_group\", \"diagnosis_group_for_analysis\"]).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo table for MRI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_dx_df = pd.merge(mri_df[[\"participant_id\",\"session\",\"MRI_age\"]], dx_df[[\"participant_id\",\"Final impression / Impression finale\", \"diagnosis_certainty\",\"diagnosis_group_for_analysis\"]], on=[\"participant_id\"], how=\"left\").drop_duplicates()\n",
    "\n",
    "mri_dx_demo_df = pd.merge(mri_dx_df, demo_var_df, on = [\"participant_id\"], how=\"left\")\n",
    "mri_dx_demo_df = mri_dx_demo_df[(mri_dx_demo_df[\"session\"]==\"ses-01\") &\n",
    "                                (mri_dx_demo_df[\"diagnosis_group_for_analysis\"].isin([\"PD\",\"control\"]))].copy()\n",
    "\n",
    "mri_dx_demo_df.groupby([\"diagnosis_group_for_analysis\",\"sex\",\"session\"]).count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_dx_demo_df.groupby([\"diagnosis_group_for_analysis\",\"session\"])[\"MRI_age\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edu_years_map = {\"< 6\": 5, \"20+\": 21}\n",
    "mri_dx_demo_df[\"education_yrs\"] = mri_dx_demo_df[\"education\"].replace(edu_years_map).fillna(0).astype(int)\n",
    "mri_dx_demo_df.loc[mri_dx_demo_df[\"education_yrs\"] <= 12,\"education_group\"] = \"<=12\"\n",
    "mri_dx_demo_df.loc[mri_dx_demo_df[\"education_yrs\"] > 12,\"education_group\"] = \">12\"\n",
    "\n",
    "mri_dx_demo_df.groupby([\"diagnosis_group_for_analysis\",\"education_group\",\"session\"])[\"education_group\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing_subs = [\"MNI0245\",\n",
    "# \"MNI0255\",\n",
    "# \"MNI0280\",\n",
    "# \"MNI0301\",\n",
    "# \"MNI0313\",\n",
    "# \"MNI0336\",\n",
    "# \"MNI0359\",\n",
    "# \"MNI0399\", #missing need to copy from DICOM\n",
    "# \"PD00910\",\n",
    "# \"PD01199\",\n",
    "# \"PD01578\",\n",
    "# \"PD01709\",\n",
    "# \"PD01715\",\n",
    "# \"PD01758\"]\n",
    "\n",
    "# - UPDRS --> MDS-updrs_cols\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign \"baseline-visit\" tag \n",
    "- Number of participants at baseline: 271\n",
    "- Criteria: +/- 6 months from MRI ses-01 date        \n",
    "    - updrs_age:113\n",
    "    - moca_age:181\n",
    "    - neuropsy_age:234\n",
    "- +/- 3 months\n",
    "    - updrs_age:104\n",
    "    - moca_age:166\n",
    "    - neuropsy_age:229\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_tagged_df = tabular_df.copy()\n",
    "baseline_tagged_df = pd.merge(baseline_tagged_df, demo_var_df[[\"participant_id\", \"recruitment_cohort\", \"enrollment_group\"]], on=[\"participant_id\"], how=\"left\").drop_duplicates()\n",
    "\n",
    "baseline_participants = baseline_tagged_df[baseline_tagged_df[\"redcap_event_name\"]==baseline_event_name][\"participant_id\"].unique()\n",
    "\n",
    "# insert Dx and MR_age for legacy-updrs3 and legacy-moca based on baseline MR_age for these participants\n",
    "legacy_updrs_participants = baseline_tagged_df[baseline_tagged_df[\"redcap_event_name\"].isin([\"legacy-updrs3\"])][\"participant_id\"].unique()\n",
    "legacy_updrs_participants = set(baseline_participants) & set(legacy_updrs_participants)\n",
    "legacy_moca_participants = baseline_tagged_df[baseline_tagged_df[\"redcap_event_name\"].isin([\"legacy-moca\"])][\"participant_id\"].unique()\n",
    "legacy_moca_participants = set(baseline_participants) & set(legacy_moca_participants)\n",
    "\n",
    "print(f\"Number of baseline participants with legacy-updrs3: {len(legacy_updrs_participants)}\")\n",
    "print(f\"Number of baseline participants with legacy-moca: {len(legacy_moca_participants)}\")\n",
    "\n",
    "for legacy_participant_id in legacy_updrs_participants:\n",
    "    baseline_dx = baseline_tagged_df[(baseline_tagged_df[\"participant_id\"]==legacy_participant_id) &\n",
    "                                    (baseline_tagged_df[\"redcap_event_name\"]==baseline_event_name)][\"diagnosis_group_for_analysis\"].values[0]\n",
    "    baseline_tagged_df.loc[(baseline_tagged_df[\"participant_id\"]==legacy_participant_id) &\n",
    "                            (baseline_tagged_df[\"redcap_event_name\"]==\"legacy-updrs3\"), \"diagnosis_group_for_analysis\"] = baseline_dx\n",
    "    \n",
    "    baseline_mri_age = baseline_tagged_df[(baseline_tagged_df[\"participant_id\"]==legacy_participant_id) &\n",
    "                                          (baseline_tagged_df[\"redcap_event_name\"]==baseline_event_name)][\"MRI_age\"].values[0]\n",
    "    baseline_tagged_df.loc[(baseline_tagged_df[\"participant_id\"]==legacy_participant_id) & \n",
    "                           (baseline_tagged_df[\"redcap_event_name\"]==\"legacy-updrs3\"), \"MRI_age\"] = baseline_mri_age\n",
    "    \n",
    "for legacy_participant_id in legacy_moca_participants:\n",
    "    baseline_dx = baseline_tagged_df[(baseline_tagged_df[\"participant_id\"]==legacy_participant_id) &\n",
    "                                    (baseline_tagged_df[\"redcap_event_name\"]==baseline_event_name)][\"diagnosis_group_for_analysis\"].values[0]\n",
    "    baseline_tagged_df.loc[(baseline_tagged_df[\"participant_id\"]==legacy_participant_id) &\n",
    "                            (baseline_tagged_df[\"redcap_event_name\"]==\"legacy-moca\"), \"diagnosis_group_for_analysis\"] = baseline_dx\n",
    "    \n",
    "    baseline_mri_age = baseline_tagged_df[(baseline_tagged_df[\"participant_id\"]==legacy_participant_id) &\n",
    "                                          (baseline_tagged_df[\"redcap_event_name\"]==baseline_event_name)][\"MRI_age\"].values[0]\n",
    "    baseline_tagged_df.loc[(baseline_tagged_df[\"participant_id\"]==legacy_participant_id) & \n",
    "                           (baseline_tagged_df[\"redcap_event_name\"]==\"legacy-moca\"), \"MRI_age\"] = baseline_mri_age\n",
    "\n",
    "\n",
    "# Filter participants for baseline+legacy visit #\"legacy-updrs3\", \"legacy-moca\"\n",
    "baseline_tagged_df = baseline_tagged_df[(baseline_tagged_df[\"redcap_event_name\"].isin([baseline_event_name, \"legacy-updrs3\", \"legacy-moca\"])) & \n",
    "            (baseline_tagged_df[\"recruitment_cohort\"] == \"QPN\") & \n",
    "            (baseline_tagged_df[\"diagnosis_group_for_analysis\"].isin([\"PD\",\"control\"]))]\n",
    "\n",
    "visit_counts = baseline_tagged_df[\"redcap_event_name\"].value_counts()\n",
    "print(f\"visit_counts: {visit_counts}\")\n",
    "baseline_tagged_df = baseline_tagged_df.sort_values(\"diagnosis_group_for_analysis\").reset_index()\n",
    "\n",
    "print(f\"Number of participants at baseline: {baseline_tagged_df['participant_id'].nunique()}\")\n",
    "\n",
    "# Find proximal visits based on age\n",
    "clinical_age_cols = [\"hy_age\", \"updrs_age\", \"moca_age\", \"neuropsy_age\"]\n",
    "proximal_participants_sessions = {}\n",
    "proximity_threshold = 6 #months\n",
    "for age_col in clinical_age_cols:\n",
    "    baseline_tagged_df[f\"{age_col}_diff\"] = 12 * (baseline_tagged_df[age_col].astype(float) - baseline_tagged_df[\"MRI_age\"].astype(float))\n",
    "    baseline_tagged_df[f\"{age_col}_diff\"] = baseline_tagged_df[f\"{age_col}_diff\"].round(2)\n",
    "    proximal_ids_session = baseline_tagged_df[baseline_tagged_df[f\"{age_col}_diff\"].abs()<=proximity_threshold][[\"participant_id\",\"redcap_event_name\"]].values\n",
    "    proximal_participants_sessions[age_col] = proximal_ids_session\n",
    "    n_proximal_participants = len(set(proximal_ids_session[:,0]))\n",
    "    print(f\"{age_col}:{n_proximal_participants}\")\n",
    "\n",
    "\n",
    "print(baseline_tagged_df[\"redcap_event_name\"].value_counts())\n",
    "baseline_tagged_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heat map of proximity \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "clinical_age_diff_col = [f\"{col}_diff\" for col in clinical_age_cols]\n",
    "\n",
    "plot_df = baseline_tagged_df.copy()\n",
    "# set high diff col to nan\n",
    "for col in clinical_age_diff_col:\n",
    "    plot_df.loc[plot_df[col].abs() > proximity_threshold, col] = np.nan\n",
    "\n",
    "plot_df[\"max_discripancy\"] = (plot_df[clinical_age_diff_col].max(axis=1) - plot_df[clinical_age_diff_col].min(axis=1)).abs()\n",
    "\n",
    "plot_df[\"Dx_int\"] = plot_df[\"diagnosis_group_for_analysis\"].replace({\"control\":0, \"PD\":1})\n",
    "\n",
    "print(f\"max_discripancy: {plot_df['max_discripancy'].max():.3}\")\n",
    "\n",
    "sns.set_theme(font_scale=1)\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    sns.heatmap(plot_df[clinical_age_diff_col + [\"max_discripancy\", \"Dx_int\"]].T, cmap=\"coolwarm\", cbar=True, center=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the cross-sectional filtered release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_df = baseline_tagged_df[index_cols + mri_cols]\n",
    "mri_df = mri_df[mri_df[\"redcap_event_name\"]==baseline_event_name].copy()\n",
    "\n",
    "dx_df = baseline_tagged_df[index_cols + dx_cols ].copy()\n",
    "dx_df = dx_df[dx_df[\"redcap_event_name\"]==baseline_event_name].copy()\n",
    "dx_df = dx_df[dx_df[\"diagnosis_group_for_analysis\"].isin([\"PD\",\"control\"])].copy()\n",
    "\n",
    "# filter assessments based on proximity to MRI\n",
    "hy_df = baseline_tagged_df[index_cols + hy_cols + [\"hy_age_diff\"]].copy()\n",
    "hy_df = hy_df[hy_df[\"hy_age_diff\"].abs()<=proximity_threshold].copy()\n",
    "\n",
    "updrs_df = baseline_tagged_df[index_cols + updrs_cols + [\"updrs_age_diff\"]].copy()\n",
    "updrs_df = updrs_df[updrs_df[\"updrs_age_diff\"].abs()<=proximity_threshold].copy()\n",
    "\n",
    "moca_df = baseline_tagged_df[index_cols + moca_cols + [\"moca_age_diff\"]].copy()\n",
    "moca_df = moca_df[moca_df[\"moca_age_diff\"].abs()<=proximity_threshold].copy()\n",
    "\n",
    "neuropsych_df = baseline_tagged_df[index_cols + neuropsych_cols + [\"neuropsy_age_diff\"]].copy()\n",
    "neuropsych_df = neuropsych_df[neuropsych_df[\"neuropsy_age_diff\"].abs()<=proximity_threshold].copy()\n",
    "\n",
    "# check and remove duplicate participants based on proximity\n",
    "# This could happen when legacy updrs or moca is available for a participant\n",
    "\n",
    "# hy\n",
    "hy_value_counts = hy_df[\"redcap_event_name\"].value_counts()\n",
    "print(f\"hy_value_counts (before): {hy_value_counts}\")\n",
    "\n",
    "if hy_df.duplicated(subset=[\"participant_id\"]).sum() > 0:\n",
    "    hy_df[\"hy_age_diff_abs\"] = hy_df[\"hy_age_diff\"].abs()\n",
    "    hy_df = hy_df.sort_values([\"participant_id\",\"hy_age_diff_abs\"]).drop_duplicates(subset=[\"participant_id\"], keep=\"first\")\n",
    "\n",
    "    hy_value_counts = hy_df[\"redcap_event_name\"].value_counts()\n",
    "    print(f\"hy_value_counts (dups dropped): {hy_value_counts}\")\n",
    "else:\n",
    "    print(\"No duplicates found in hy_df\")\n",
    "\n",
    "# updrs\n",
    "updrs_value_counts = updrs_df[\"redcap_event_name\"].value_counts()\n",
    "print(f\"updrs_value_counts (before): {updrs_value_counts}\")\n",
    "\n",
    "if updrs_df.duplicated(subset=[\"participant_id\"]).sum() > 0:\n",
    "    updrs_df[\"updrs_age_diff_abs\"] = updrs_df[\"updrs_age_diff\"].abs()\n",
    "    updrs_df = updrs_df.sort_values([\"participant_id\",\"updrs_age_diff_abs\"]).drop_duplicates(subset=[\"participant_id\"], keep=\"first\")\n",
    "\n",
    "    updrs_value_counts = updrs_df[\"redcap_event_name\"].value_counts()\n",
    "    print(f\"updrs_value_counts (dups dropped): {updrs_value_counts}\")\n",
    "else:\n",
    "    print(\"No duplicates found in updrs_df\")\n",
    "\n",
    "# moca\n",
    "moca_value_counts = moca_df[\"redcap_event_name\"].value_counts()\n",
    "print(f\"moca_value_counts (before):  {moca_value_counts}\")\n",
    "\n",
    "if moca_df.duplicated(subset=[\"participant_id\"]).sum() > 0:\n",
    "    moca_df[\"moca_age_diff_abs\"] = moca_df[\"moca_age_diff\"].abs()\n",
    "    moca_df = moca_df.sort_values([\"participant_id\",\"moca_age_diff_abs\"]).drop_duplicates(subset=[\"participant_id\"], keep=\"first\")\n",
    "\n",
    "    moca_value_counts = moca_df[\"redcap_event_name\"].value_counts()\n",
    "    print(f\"moca_value_counts (dups dropped):  {moca_value_counts}\")\n",
    "else:\n",
    "    print(\"No duplicates found in moca_df\")\n",
    "    \n",
    "# neuropsych\n",
    "neuropsych_value_counts = neuropsych_df[\"redcap_event_name\"].value_counts()\n",
    "print(f\"neuropsych_value_counts: {neuropsych_value_counts}\")\n",
    "\n",
    "# filter na rows\n",
    "mri_df = mri_df.dropna(subset=mri_cols, how='all').sort_values([\"redcap_event_name\"], ascending=False).sort_values([\"participant_id\"])\n",
    "dx_df = dx_df.dropna(subset=dx_cols, how='all').sort_values([\"redcap_event_name\"], ascending=False).sort_values([\"participant_id\"])\n",
    "hy_df = hy_df.dropna(subset=hy_cols, how='all').sort_values([\"redcap_event_name\"], ascending=False).sort_values([\"participant_id\"])\n",
    "updrs_df = updrs_df.dropna(subset=updrs_cols, how='all').sort_values([\"redcap_event_name\"], ascending=False).sort_values([\"participant_id\"])\n",
    "moca_df = moca_df.dropna(subset=moca_cols, how='all').sort_values([\"redcap_event_name\"], ascending=False).sort_values([\"participant_id\"])\n",
    "neuropsych_df = neuropsych_df.dropna(subset=neuropsych_cols, how='all').sort_values([\"redcap_event_name\"], ascending=False).sort_values([\"participant_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per Dx counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {\n",
    "    \"hy\": hy_df,\n",
    "    \"updrs\": updrs_df,\n",
    "    \"moca\": moca_df,\n",
    "    \"neuropsych\": neuropsych_df\n",
    "}\n",
    "for assesment, score_df in df_dict.items():\n",
    "    score_dx_df = pd.merge(score_df, dx_df, on=[\"participant_id\"], how=\"left\")\n",
    "    value_counts = score_dx_df.groupby([\"diagnosis_group_for_analysis\"]).count()[\"participant_id\"]\n",
    "    print(f\"{assesment}: {value_counts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mri_participants = mri_df[\"participant_id\"].nunique()\n",
    "n_mri_duplicates = mri_df.duplicated(subset=[\"participant_id\"]).sum()\n",
    "print(f\"Number of MRI participants: {n_mri_participants}, duplicates: {n_mri_duplicates}\")\n",
    "\n",
    "mri_df.to_csv(publish_mri_session_date_file, index=False)\n",
    "print(f\"Saved MRI session data to {publish_mri_session_date_file}\")\n",
    "\n",
    "n_dx_participants = dx_df[\"participant_id\"].nunique()\n",
    "n_dx_duplicates = dx_df.duplicated(subset=[\"participant_id\"]).sum()\n",
    "print(f\"Number of diagnosis participants: {n_dx_participants}, duplicates: {n_dx_duplicates}\")\n",
    "dx_df.to_csv(publish_dx_file, index=False)\n",
    "print(f\"Saved diagnosis data to {publish_dx_file}\")\n",
    "\n",
    "n_hy_participants = hy_df[\"participant_id\"].nunique()\n",
    "n_hy_duplicates = hy_df.duplicated(subset=[\"participant_id\"]).sum()\n",
    "print(f\"Number of H&Y participants: {n_hy_participants}, duplicates: {n_hy_duplicates}\")\n",
    "hy_df.to_csv(publish_hy_file, index=False)\n",
    "print(f\"Saved H&Y data to {publish_hy_file}\")\n",
    "\n",
    "n_updrs_participants = updrs_df[\"participant_id\"].nunique()\n",
    "n_updrs_duplicates = updrs_df.duplicated(subset=[\"participant_id\"]).sum()\n",
    "print(f\"Number of UPDRS participants: {n_updrs_participants}, duplicates: {n_updrs_duplicates}\")\n",
    "updrs_df.to_csv(publish_updrs_file, index=False)\n",
    "print(f\"Saved UPDRS data to {publish_updrs_file}\")\n",
    "\n",
    "n_moca_participants = moca_df[\"participant_id\"].nunique()\n",
    "n_moca_duplicates = moca_df.duplicated(subset=[\"participant_id\"]).sum()\n",
    "print(f\"Number of MoCA participants: {n_moca_participants}, duplicates: {n_moca_duplicates}\")\n",
    "\n",
    "moca_df.to_csv(publish_moca_file, index=False)\n",
    "print(f\"Saved MoCA data to {publish_moca_file}\")\n",
    "\n",
    "# neuropsych_df.to_csv(publish_neuropsych_file, index=False)\n",
    "# print(f\"Saved neuropsych data to {publish_neuropsych_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mark NM participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NM_participants_df = pd.read_csv(neuromelanin_participant_list_csv)\n",
    "NM_participants_df = NM_participants_df.rename(columns={\"PSCID\":\"participant_id\"})\n",
    "NM_participants = NM_participants_df[\"participant_id\"].unique()\n",
    "print(f\"Number of Neuromelanin participants: {len(NM_participants)}\")\n",
    "\n",
    "NM_participants_df.loc[NM_participants_df[\"Visit Label\"] == \"MRI01\", \"session\"] = \"ses-01\"\n",
    "NM_participants_df.loc[NM_participants_df[\"Visit Label\"] == \"MRI02\", \"session\"] = \"ses-02\"\n",
    "NM_participants_df.loc[NM_participants_df[\"Visit Label\"] == \"MRI03\", \"session\"] = \"ses-03\"\n",
    "\n",
    "# session wise counts\n",
    "session_counts = NM_participants_df[\"session\"].value_counts()\n",
    "print(f\"session_counts: {session_counts}\")\n",
    "\n",
    "# compare with mri_df\n",
    "mri_participants = mri_df[\"participant_id\"].unique()\n",
    "print(f\"Number of participants with MRI data: {len(mri_participants)}\")\n",
    "\n",
    "# participants in NM cohort but not in MRI cohort\n",
    "NM_participants_not_in_mri = set(NM_participants) - set(mri_participants)\n",
    "print(f\"Number of NM participants not in MRI cohort: {len(NM_participants_not_in_mri)}\")\n",
    "\n",
    "# participants in NM cohort and in MRI cohort\n",
    "NM_participants_in_mri = set(NM_participants) & set(mri_participants)\n",
    "print(f\"Number of NM participants in MRI cohort: {len(NM_participants_in_mri)}\")\n",
    "\n",
    "# participants in MRI cohort but not in NM cohort\n",
    "mri_participants_not_in_NM = set(mri_participants) - set(NM_participants)\n",
    "print(f\"Number of MRI participants not in NM cohort: {len(mri_participants_not_in_NM)}\")\n",
    "\n",
    "# save NM participants\n",
    "NM_participants_df.to_csv(f\"{tabular_data_release_dir}/recruitment/neuromelanin_participants_VM.csv\", index=False)\n",
    "\n",
    "NM_participants_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate bagel\n",
    "\n",
    "- Merge demographic and assessment variables \n",
    "- get age from MRI\n",
    "- Add bids participant_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_cols = [\"participant_id\", \"redcap_event_name\"]\n",
    "\n",
    "bagel_assessment_cols = {\n",
    "    \"age\": [\"MRI_age\"],\n",
    "    \"dx\": [\"diagnosis_group_for_analysis\", \"diagnosis_age\"],\n",
    "    \"hy\": ['Hoehn and Yahr Stage: ', 'hy_age'],\n",
    "    \"updrs\": ['Part I: Non-Motor Aspects of Experiences of Daily Living (nM-EDL)',\n",
    "            'Part II: Motor Aspects of Experiences of Daily Living (M-EDL)',\n",
    "            'Part III: Motor Examination', 'Part IV: Motor Complications',\n",
    "            'Part IV: Motor Complications', 'updrs_age'],\n",
    "    \"moca\": [\"TOTAL SCORE (make sure to include extra point for 12 years or less of education):    \"\n",
    "            \"SCORE TOTAL (assurez-vous d'inclure un point supplémentaire pour 12 ans ou moins d'éducation) : \",\n",
    "            \"moca_age\"]\n",
    "}\n",
    "\n",
    "bagel_df = demo_var_without_dob_df.copy()\n",
    "\n",
    "# merge with assessments\n",
    "for var, cols in bagel_assessment_cols.items():\n",
    "    _df = tabular_df[index_cols + cols].copy()\n",
    "    bagel_df = pd.merge(bagel_df, _df, on=index_cols, how=\"left\")\n",
    "\n",
    "# add bids_id prefix\n",
    "\n",
    "# Add additional BIDSified subjects not in the QPN manifest\n",
    "additional_participants = ['PD01662', 'MNI0147', 'PD01687', 'MNI0482', 'PD01686', 'PD01253']   \n",
    "additional_participants_df = pd.DataFrame(columns=bagel_df.columns)\n",
    "additional_participants_df[\"participant_id\"] = additional_participants\n",
    "additional_participants_df[\"redcap_event_name\"] = \"Baseline (Arm 1: Unknown)\"\n",
    "\n",
    "bagel_df = pd.concat([bagel_df, additional_participants_df], axis=\"rows\", ignore_index=True)\n",
    "\n",
    "bagel_df[\"bids_participant_id\"] = \"sub-\" + bagel_df[\"participant_id\"].astype(str)\n",
    "\n",
    "n_bagel_participants = bagel_df[\"participant_id\"].nunique()\n",
    "n_bagel_events = bagel_df[\"redcap_event_name\"].nunique()\n",
    "\n",
    "print(f\"Number of participants with BAGEL data: {n_bagel_participants}\")\n",
    "print(f\"Number of events with BAGEL data: {n_bagel_events}\")\n",
    "\n",
    "\n",
    "# save bagel\n",
    "print(f\"Saving bagel data to {bagel_file}\")\n",
    "bagel_df.to_csv(bagel_file, index=False, sep=\"\\t\")\n",
    "\n",
    "bagel_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test neuropsy norming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuropsych_demo_df = pd.merge(neuropsych_df, demo_var_df[[\"participant_id\",\"sex\",\"education\"]], on=[\"participant_id\"], how=\"left\")\n",
    "# \"Sex (1=men; 2=women)\"\n",
    "neuropsych_demo_df[\"Sex (1=men; 2=women)\"] = neuropsych_demo_df[\"sex\"].replace({\"Male/Masculin\":1, \"Female/Féminin\":2})\n",
    "neuropsych_demo_df[\"Age at time of assessment\"] = neuropsych_demo_df[\"neuropsy_age\"]\n",
    "edu_years_map = {\"< 6\": 5, \"20+\": 21}\n",
    "neuropsych_demo_df[\"education\"]  = neuropsych_demo_df[\"education\"].replace(edu_years_map).astype(float)\n",
    "neuropsych_demo_df[\"Education level (primary school = 6 years, high school = 12, cegep = 14, bachelor = 17, master = 19, phD = 23\"] = neuropsych_demo_df[\"education\"]\n",
    "neuropsych_demo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuropsych_demo_file = '/home/nikhil/projects/Parkinsons/qpn//releases/Oct_2024//tabular//assessments/neuropsych_demo.csv'\n",
    "neuropsych_demo_df.to_csv(neuropsych_demo_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuropsych_demo_df[neuropsych_demo_df.columns[neuropsych_demo_df.columns.str.contains(\"Copy raw\")]].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nipoppy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
