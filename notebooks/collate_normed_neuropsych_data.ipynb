{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook to collate the normed data from different assessments in neuropsych battery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"/home/nikhil/projects/Parkinsons/qpn\"\n",
    "\n",
    "# manifest\n",
    "tabular_dir = f\"{dataset_dir}/tabular\"\n",
    "manifest_file = f\"{tabular_dir}/manifest.csv\"\n",
    "\n",
    "# neuropysch\n",
    "neuropych_dir = f\"{tabular_dir}/assessments/neuropysch/RPQ_neuropsych_norming/\"\n",
    "neuropych_json_dir = f\"{neuropych_dir}/JSONs\"\n",
    "normed_scores_dir = f\"{neuropych_dir}/normed_scores\"\n",
    "\n",
    "participant_id_col = \"Patient #\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read manifest (available subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest = pd.read_csv(manifest_file)\n",
    "qpn_participants = manifest[\"participant_id\"].unique()\n",
    "sessions = manifest[\"session\"].unique()\n",
    "\n",
    "print(f\"n_participants: {len(qpn_participants)}, unique sessions: {sessions}\")\n",
    "manifest.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check available normed assessments and their config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed issues:\n",
    "\"normed_data\" path for:\n",
    "\n",
    "    i. Stroop_DKefs_Cond_3_INK_Time_sec.xlsx --> Stroop_DKefs_Cond_3_INK_Time_Normed.xlsx\n",
    "    ii. Stroop_DKefs_Cond_1_COLORS_Time_sec.xlsx --> Stroop_DKefs_Cond_1_COLORS_Time_Normed.xlsx\n",
    "    iii. Stroop_DKefs_Cond_3_Total_errors.xlsx --> Stroop_DKefs_Cond_3_Total_errors_Normed.xlsx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_files = os.listdir(neuropych_json_dir)\n",
    "print(f\"n_json_files: {len(json_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_assessment_info(json_path):\n",
    "    # json_file = os.path.basename(json_path)\n",
    "    info = pd.read_json(json_path)\n",
    "    instrument = info[\"instrument\"]\n",
    "    norming_procedure = instrument[\"norming_procedure\"]\n",
    "    \n",
    "    raw_score_col = instrument[\"raw_score_name\"]\n",
    "    normed_score_col = instrument[\"normed_score_name\"]\n",
    "    \n",
    "    data_paths = info[\"data_paths\"]\n",
    "    normed_data_path = data_paths[\"normed_data\"]\n",
    "    normed_file_name = os.path.basename(normed_data_path)\n",
    "\n",
    "    return raw_score_col, normed_score_col, normed_file_name, norming_procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix participant ids\n",
    "participant_id_replace_dict = {\"PD00119/T1\":\"PD00119\"}\n",
    "participant_id_drop_list = [\"PD00119/T2\",\"PD00\"]\n",
    "# collate normed scores\n",
    "scores_df_list = []\n",
    "for json_file in json_files:\n",
    "    json_path = f\"{neuropych_json_dir}/{json_file}\"\n",
    "    print(f\"assessment: {json_file}\")\n",
    "    if json_file in [\"TMT_AB_contrast_config.json\"]:\n",
    "        print(f\"Ignoring contrast instrument with two raw score cols: {json_file}\")\n",
    "    else:\n",
    "        raw_score_col, normed_score_col, normed_file_name, norming_procedure = get_assessment_info(json_path)\n",
    "        normed_data_file = f\"{normed_scores_dir}/{normed_file_name}\"\n",
    "        _df = pd.read_excel(f\"{normed_data_file}\")\n",
    "        # Fix participant id\n",
    "        _df[participant_id_col] = _df[participant_id_col].replace(participant_id_replace_dict)\n",
    "        _df = _df[~_df[participant_id_col].isin(participant_id_drop_list)]\n",
    "        _df = _df[[participant_id_col, raw_score_col, normed_score_col]]\n",
    "        \n",
    "        ## drop duplicates (keep first i.e. baseline assessment for each participant)\n",
    "        _df = _df.drop_duplicates(subset=[participant_id_col],keep=\"first\")\n",
    "        _df[\"norming_procedure\"] = norming_procedure\n",
    "        _df[participant_id_col] = _df[participant_id_col].astype(str).str.strip()\n",
    "        _df = _df.rename(columns={normed_score_col: \"normed_score\", raw_score_col: \"raw_score\"})\n",
    "        _df[\"assessment\"] = json_file.split(\".\")[0]\n",
    "        scores_df_list.append(_df)\n",
    "        \n",
    "scores_df = pd.concat(scores_df_list, axis=0)\n",
    "\n",
    "scores_df.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.melt(scores_df, id_vars=[participant_id_col, \"assessment\", \"norming_procedure\"], \n",
    "                  value_vars=[\"normed_score\", \"raw_score\"], value_name=\"score\", var_name=\"score_type\")\n",
    "plot_df = plot_df.sort_values(by=[\"score_type\", \"norming_procedure\", \"assessment\"])\n",
    "col_order = [\"raw_score\",\"normed_score\"]\n",
    "sns.set(font_scale=1.5)\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    g = sns.catplot(x=\"score\" ,y=\"assessment\", col=\"score_type\", hue=\"norming_procedure\", palette=\"Set1\",  \n",
    "                    data=plot_df, col_order=col_order, \n",
    "                    height=10, kind=\"strip\", sharex=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find missing participants per assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_availability_df = scores_df.groupby([\"assessment\"]).count().reset_index().drop(columns=[\"norming_procedure\"])\n",
    "score_availability_df = score_availability_df.rename(columns={\"Patient #\": \"recruitment_count\",\n",
    "                                                              \"raw_score\": \"raw_score_count\",\n",
    "                                                              \"normed_score\": \"normed_score_count\"})\n",
    "\n",
    "score_availability_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_score_wide_df = scores_df.pivot(index=participant_id_col, columns=\"assessment\", values=\"raw_score\")\n",
    "normed_score_wide_df = scores_df.pivot(index=participant_id_col, columns=\"assessment\", values=\"normed_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df.to_csv(f\"{neuropych_dir}/collated_scores_longform.csv\", index=False)\n",
    "raw_score_wide_df.to_csv(f\"{neuropych_dir}/raw_score_wideform.csv\", index=True)\n",
    "normed_score_wide_df.to_csv(f\"{neuropych_dir}/normed_score_wideform.csv\", index=True)\n",
    "score_availability_df.to_csv(f\"{neuropych_dir}/score_availability.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with manifest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurospych_participants = scores_df[participant_id_col].unique()\n",
    "print(f\"n_neurospych_participants: {len(neurospych_participants)}\")\n",
    "scores_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuropsy_and_qpn = set(neurospych_participants ) & set(qpn_participants)\n",
    "not_in_qpn = set(neurospych_participants ) - set(qpn_participants)\n",
    "not_in_neuropsy = set(qpn_participants) - set(neurospych_participants )\n",
    "\n",
    "print(f\"n_neuropsy_and_qpn: {len(neuropsy_and_qpn)}, n_not_in_qpn: {len(not_in_qpn)}, n_not_in_neuropsy: {len(not_in_neuropsy)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nipoppy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
